{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогностична модель з використанням методу опорних векторів (SVM)\n",
    "\n",
    "Алгоритми навчання за допомогою методу опорних векторів (SVM) буде використовуватись для побудови прогностичної моделі. SVM - один з найпопулярніших алгоритмів класифікації і має елегантний спосіб перетворення нелінійних даних, щоб можна було використовувати лінійний алгоритм для пристосування лінійної моделі до даних.\n",
    "\n",
    "Кернелізовані методи опорних векторів є потужними моделями і добре працюють на різних наборах даних.\n",
    "1. SVM допускають складні межі прийняття рішень, навіть якщо дані мають лише кілька ознак.\n",
    "2. Вони добре працюють над маломірними та багатомірними даними (мало і багато ознак), але не дуже масштабують кількість вибірок.\n",
    "> **Запуск SVM на даних до 10 000 зразків може працювати добре, але робота з наборами даних розміром 100 000 і більше вимагає великих обчислювальних потужностей та великих обсягів пам'яті.**\n",
    "\n",
    "3. SVM вимагає ретельної обробки даних та налаштування параметрів. Саме тому в основному натомість використовують моделі на основі дерев, такі як \"випадковий ліс\" або збільшення градієнтів (для яких потрібна невелика або взагалі ніяка попередня обробка) у багатьох програмах.\n",
    "4. Моделі SVM важко перевіряти; може бути важко зрозуміти, чому було зроблено конкретний прогноз, і складно пояснити модель неексперту.\n",
    "\n",
    "#### Важливі параметри\n",
    "Важливими параметрами SVM-ядер є:\n",
    "* Параметр регуляризації C;\n",
    "* Вибір ядра, (лінійна, функція радіальної основи (RBF) або поліном);\n",
    "* Параметри ядра.\n",
    "\n",
    "gamma та C контролюють складність моделі, причому великі значення в обох призводять до більш складної моделі. Тому налаштування для двох параметрів зазвичай сильно співвідносяться, і C, і gamma повинні коригуватись разом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#бібліотеки для обробки даних\n",
    "import pandas as pd #обробка даних, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "## Контрольоване навчання.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# візуалізація\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4) \n",
    "#plt.rcParams['axes.titlesize'] = 'large'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/clean-data.csv', index_col=False)\n",
    "data.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#призначення предиктору до змінної типу ndarray (matrix)\n",
    "array = data.values\n",
    "X = array[:,1:31] # ознаки\n",
    "y = array[:,0]\n",
    "\n",
    "#перетворення класових міток з рядкового типу (M та B) в цілочисельний\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Нормалізація даних\n",
    "scaler =StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класифікація та крос-валідація\n",
    "\n",
    "Як вже було сказано в розділі 3 \"Обробка даних\" розбиття даних на тестові та навчальні набори є важливим для уникнення надмірного використання ресурсів. Це дозволяє узагальнити реальні, раніше невідомі дані. Крос-валідація продовжує цю ідею. Замість того, щоб мати один набір тестових/навчальних даних, вказуються **так звані піднабори**, щоб розділити дані на піднабори однакового розміру.\n",
    "\n",
    "* Навчання відбувається шляхом вибору усіх піднаборів за винятком одного (зразок).\n",
    "* По завершенні навчання перевіряється працездатність відповідної моделі, використовуючи зразок.\n",
    "\n",
    "* Потім зразок використовується для навчання разом з усіма іншими піднаборами, а інший піднабір обирається як новий зразок.\n",
    "\n",
    "* Навчання знову повторюється з рештою піднаборів і вимірюється результативність за допомогою зразка. Цей процес повторюється до тих пір, поки кожен піднабір не може бути тестовим або зразком.\n",
    "\n",
    "* Очікувана продуктивність класифікатора, яка називається помилкою крос-валідації, є просто середнім показником помилок, обчисленим для кожного зразку.\n",
    "\n",
    "Цей процес демонструється спочатку виконанням стандартного розбиття навчальних/тестових даних, а потім обчисленням помилки крос-валідації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Розділення записів на навчальні та тестові набори\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3, random_state=2, stratify=y)\n",
    "\n",
    "# 6. Створення SVM класифікатора та його навчання на 70% даних\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 7. Аналіз точності прогнозів на 30% тестових зразків\n",
    "classifier_score = clf.score(X_test, y_test)\n",
    "print '\\nThe classifier accuracy score is {:03.2f}\\n'.format(classifier_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для отримання кращої міри точності прогнозування, можна послідовно розділити дані на піднабори, які будуть використовуватись для тренування та тестування:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# середній показник крос-валідації 3 піднаборів за допомогою оцінки SVC\n",
    "n_folds = 3\n",
    "cv_error = np.average(cross_val_score(SVC(), Xs, y, cv=n_folds))\n",
    "print '\\nThe {}-fold cross-validation accuracy score for this classifier is {:.2f}\\n'.format(n_folds, cv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наведені вище оцінки базуються на використанні всього набору ознак. Тепер буде використовуватись стратегія вибору ознак на основі кореляції, щоб оцінити ефект використання трьох ознак, які мають найкращу кореляцію з мітками класів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "clf2 = make_pipeline(SelectKBest(f_regression, k=3),SVC(probability=True))\n",
    "\n",
    "scores = cross_val_score(clf2, Xs, y, cv=3)\n",
    "\n",
    "# середній показник крос-валідації 3 піднаборів за допомогою оцінки SVC\n",
    "n_folds = 3\n",
    "cv_error = np.average(cross_val_score(SVC(), Xs, y, cv=n_folds))\n",
    "print '\\nThe {}-fold cross-validation accuracy score for this classifier is {:.2f}\\n'.format(n_folds, cv_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print scores\n",
    "avg = (100*np.mean(scores), 100*np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print \"Average score and uncertainty: (%.2f +- %.3f)%%\"%avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "З наведених вище результатів видно, що для побудови моделі, яка працює аналогічно моделям, заснованих на використанні всього набору ознак, потрібно лише частина ознак. Вибір ознак є важливою частиною процесу створення моделі, на яку завжди потрібно звертати особливу увагу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точність моделі: ROC-крива (робоча характеристика приймача)\n",
    "\n",
    "У статистичному моделюванні та машинному навчанні загальноприйнятим показником ефективності точності моделі для задач бінарної класифікації є площа під ROC-кривою (AUC).\n",
    "\n",
    "Щоб зрозуміти, яку інформацію передає крива ROC, необхідно розглянути \"матрицю плутанини\", яка по суті є двовимірною таблицею, де модель класифікатора знаходиться на одній осі (вертикальній), а основна істина - на іншій (горизонтальній) осі, як показано нижче. Будь-яка з цих осей може приймати два значення.\n",
    "\n",
    "Модель виводить \"+\" | Модель виводить \"-\" --- | --- | --- True positive | False negative | ** Фактичні дані: \"+\" ** False positive | True negative | Фактичні дані: \"-\"\n",
    "На ROC-кривій, графік “True Positive Rate” на осі Y та “False Positive Rate” на осі X, де значення “true positive”, “false negative”, “false positive”, та “true negative” є подіями (або їх ймовірностями) як описано вище. The rates are defined according to the following.\n",
    "> * True positive rate (or sensitivity)}: tpr = tp / (tp + fn)\n",
    "> * False positive rate:       fpr = fp / (fp + tn)\n",
    "> * True negative rate (or specificity): tnr = tn / (fp + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# матриця плутанини допомагає візуалізувати виконання алгоритму.\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(cm, cmap=plt.cm.Reds, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "     for j in range(cm.shape[1]):\n",
    "         ax.text(x=j, y=i,\n",
    "                s=cm[i, j], \n",
    "                va='center', ha='center')\n",
    "plt.xlabel('Predicted Values', )\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "print(classification_report(y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результати спостережень\n",
    "Є два можливі передбачувані класи: \"1\" і \"0\". Злоякісний = 1 (вказує на наявність ракових клітин) і доброякісний\n",
    "= 0 (вказує на їх відсутність).\n",
    "\n",
    "* Загалом класифікатор виконав 174 прогнозувань (тобто 174 пацієнтів було протестувано на наявність раку молочної залози).\n",
    "* З цих 174 випадків класифікатор передбачив \"1\" 58 разів, а \"0\" - 113 разів.\n",
    "* Насправді 64 пацієнта у вибірці мають захворювання, а 107 пацієнтів - ні.\n",
    "\n",
    "#### Норми, обчислені за допомогою матриці хибності\n",
    "1. **Accuracy**: наскільки точним є класифікатор?\n",
    "    * (TP+TN)/total = (57+106)/171 = 0.95\n",
    "\n",
    "2. **Misclassification Rate**: як часто виникають помилки?\n",
    "    * (FP+FN)/total = (1+7)/171 = 0.05 (еквівалентно 1 - Точність)\n",
    "    \n",
    "3. **True Positive Rate**: коли насправді 1, то як часто прогнозується 1 - наявність раку?\n",
    "    * * TP/actual yes = 57/64 = 0.89\n",
    "    \n",
    "4. **False Positive Rate**: коли насправді 0 - відсутність раку, то як часто прогнозується 1 - наявність раку?\n",
    "    * FP/actual no = 1/107 = 0.01\n",
    "    \n",
    "5. **Specificity**: коли насправді 0, то як часто прогнозується 0 - відсутність раку?\n",
    "    * TN/actual no = 106/107 = 0.99 (еквівалентно 1 - False Positive Rate)\n",
    "    \n",
    "6. **Precision**: коли визначається наявність раку - 1, то як часто це істина?\n",
    "    * TP/predicted yes = 57/58 = 0.98\n",
    "    \n",
    "7. **Prevalence**: як часто умова 1 насправді трапляється у зразках?\n",
    "    * actual yes/total = 64/171 = 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# ROC\n",
    "plt.figure(figsize=(10,8))\n",
    "probas_ = clf.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.axes().set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для точок вище діагоналі, tpr > fpr, модель говорить, що ви перебуваєте в зоні, де ви працюєте краще, ніж випадково. Наприклад, припустимо tpr = 0,99 і fpr = 0,01, Тоді ймовірність опинитися в справжній позитивній групі становить (0,99 / (0,99 + 0,01)) = 99%. Крім того, тримаючи fpr постійною, легко помітити, що чим більше вертикально ви розміщені по діагоналі, тим краща модель класифікації."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
