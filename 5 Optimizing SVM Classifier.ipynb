{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимізація SVM класифікатора\n",
    "\n",
    "Параметри моделей машинного навчання вказані так, щоб їх поведінку можна було налаштувати згідно заданій проблемі. Моделі можуть мати багато параметрів, і пошук найкращої комбінації параметрів може розглядатися як проблема пошуку. В даному розділі налаштування параметрів моделі класифікації SVM відбувається за допомогою scikit-learn.\n",
    "\n",
    "#### Завантаження бібліотек та даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Біболіотеки для обробки даних\n",
    "import pandas as pd #обробка даних, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "## Контрольоване навчання.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# візуалізація\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4) \n",
    "#plt.rcParams['axes.titlesize'] = 'large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Побудова моделі прогнозування та оцінка за допомогою 5-крокової валідації, використовуючи класифікатор SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/clean-data.csv', index_col=False)\n",
    "data.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Призначення предикторів до змінної типу ndarray (matrix)\n",
    "array = data.values\n",
    "X = array[:,1:31]\n",
    "y = array[:,0]\n",
    "\n",
    "#перетворення класових міток з рядкового в цілочисельне представлення\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Нормалізація даних\n",
    "scaler =StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# вилучення ознак\n",
    "pca = PCA(n_components=10)\n",
    "fit = pca.fit(Xs)\n",
    "X_pca = pca.transform(Xs)\n",
    "\n",
    "# 5. Розділення записів на тестові та навчальні.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=2, stratify=y)\n",
    "\n",
    "# 6. Створення класифікатора SVM та його навчання на 70% даних.\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    " #7. Аналіз точності прогнозування на 30% тестових даних.\n",
    "classifier_score = clf.score(X_test, y_test)\n",
    "print '\\nThe classifier accuracy score is {:03.2f}\\n'.format(classifier_score)\n",
    "\n",
    "clf2 = make_pipeline(SelectKBest(f_regression, k=3),SVC(probability=True))\n",
    "scores = cross_val_score(clf2, X_pca, y, cv=3)\n",
    "\n",
    "# середня оцінка 5-крокової крос-валідації, використовуючи оцінювач SVC.\n",
    "n_folds = 5\n",
    "cv_error = np.average(cross_val_score(SVC(), X_pca, y, cv=n_folds))\n",
    "print '\\nThe {}-fold cross-validation accuracy score for this classifier is {:.2f}\\n'.format(n_folds, cv_error)\n",
    "\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred ))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(cm, cmap=plt.cm.Reds, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "     for j in range(cm.shape[1]):\n",
    "         ax.text(x=j, y=i,\n",
    "                s=cm[i, j], \n",
    "                va='center', ha='center')\n",
    "plt.xlabel('Predicted Values', )\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Важливість оптимізації класифікатора\n",
    "\n",
    "Можна налаштувати 2 ключових параметри класифікатора SVM:\n",
    "1. Значення С (межа)\n",
    "2. Тип ядра\n",
    "\n",
    "Типовим для SVM (клас SVC) є використання ядра Radial Basis Function (RBF) зі значенням C, встановленим на 1,0. Як і в KNN, пошук буде здійснюватися по сітці, використовуючи 10-кратну крос-валідацію зі стандартизованою копією навчального набору даних. Буде використано ряд більш простих типів ядер та значень C із меншим зміщенням та більшою зміщеністю (менше та більше 1,0 відповідно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# навчання класифікаторів\n",
    "kernel_values = [ 'linear' ,  'poly' ,  'rbf' ,  'sigmoid' ]\n",
    "param_grid = {'C': np.logspace(-3, 2, 6), 'gamma': np.logspace(-3, 2, 6),'kernel': kernel_values}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.probability = True\n",
    "clf = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "#print(cm)\n",
    "print(classification_report(y_test, y_pred ))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(cm, cmap=plt.cm.Reds, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "     for j in range(cm.shape[1]):\n",
    "         ax.text(x=j, y=i,\n",
    "                s=cm[i, j], \n",
    "                va='center', ha='center')\n",
    "plt.xlabel('Predicted Values', )\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Межі рішення різних класифікаторів\n",
    "Межі рішення, зроблені лінійними, гауссовими та поліноміальними класифікаторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "def decision_plot(X_train, y_train, n_neighbors, weights):\n",
    "       h = .02  # розмір кроку в сітці\n",
    "\n",
    "Xtrain = X_train[:, :2] # беремо лише перші дві ознаки\n",
    "\n",
    "#================================================================\n",
    "# Створення карт кольорів\n",
    "#================================================================\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "\n",
    "#================================================================\n",
    "# створення екземпляру SVM та даних з виправленням\n",
    "# дані не масштабуються, оскільки будуються вектори підтримки\n",
    "#================================================================\n",
    "\n",
    "C = 1.0  # регулюючий параметр SVM\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=0, gamma=0.1, C=C).fit(Xtrain, y_train)\n",
    "rbf_svc = SVC(kernel='rbf', gamma=0.7, C=C).fit(Xtrain, y_train)\n",
    "poly_svc = SVC(kernel='poly', degree=3, C=C).fit(Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 9) \n",
    "plt.rcParams['axes.titlesize'] = 'large'\n",
    "    \n",
    "    # створення сітки для побудови\n",
    "x_min, x_max = Xtrain[:, 0].min() - 1, Xtrain[:, 0].max() + 1\n",
    "y_min, y_max = Xtrain[:, 1].min() - 1, Xtrain[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# надписи для графіків\n",
    "titles = ['SVC with linear kernel',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, clf in enumerate((svm, rbf_svc, poly_svc)):\n",
    "    # межі рішення позначені кольорами\n",
    "    # точка на сітці [x_min, x_max]x[y_min, y_max].\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # зображення результатів на кольоровому графіку\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "    # зображення на графіку точок навчання\n",
    "    plt.scatter(Xtrain[:, 0], Xtrain[:, 1], c=y_train, cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel('radius_mean')\n",
    "    plt.ylabel('texture_mean')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Висновок\n",
    "\n",
    "Даний розділ демонструє моделювання раку молочної залози як завдання класифікації за допомогою SVM.\n",
    "\n",
    "SVM працює краще, коли набір даних стандартизований: всі атрибути мають середнє значення нуля та стандартне відхилення - одиницю. Ми можемо обчислити це з усього навчального набору даних і застосувати те саме перетворення до вхідних атрибутів з тестового набору даних."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
