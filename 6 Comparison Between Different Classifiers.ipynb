{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоматизація процесу машинного навчання використовуючи конвеєри (pipelines)\n",
    "\n",
    "У проекті машинного навчання є стандартні робочі процеси, які можна автоматизувати. В Python scikit-learn, конвеєри (pipelines) допомагають чітко визначити та автоматизувати ці робочі процеси.\n",
    "* Конвеєри допомагають подолати поширені проблеми, такі як неповнота даних тощо;\n",
    "* Python scikit-learn надає утиліту Pipeline, яка допомагає автоматизувати робочі процеси машинного навчання;\n",
    "* Конвеєри працюють, дозволяючи лінійній послідовності перетворень даних зв'язуватись в процес моделювання.\n",
    "\n",
    "### Підготовка даних та моделювання конвеєру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Створення pipeline, що стандартизує дані та створює модель\n",
    "# завантаження бібліотек для обробки даних\n",
    "import pandas as pd # обробка даних, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# візуалізація\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4) \n",
    "#plt.rcParams['axes.titlesize'] = 'large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оцінка алгоритмів\n",
    "Потрібно створити деякі моделі даних та оцінити їх точність за невидимими даними. Ось що буде висвітлено на цьому кроці:\n",
    "1. Відокремлення набору даних перевірки;\n",
    "2. Налаштування тестового набору для використання 10-кратної крос-валідації;\n",
    "3. Побудова 5 різних моделей;\n",
    "4. Вибір найкращої моделі.\n",
    "\n",
    "### 1.0 Набір даних валідації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#завантаження даних\n",
    "data = pd.read_csv('data/clean-data.csv', index_col=False)\n",
    "data.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "\n",
    "# розділення набору даних валідації\n",
    "array = data.values\n",
    "X = array[:,1:31]\n",
    "y = array[:,0]\n",
    "\n",
    "# розділення тестових та навчальних даних\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "\n",
    "# перетворення класових міток з рядкових у цілочисельний тип\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Оцінка алгоритмів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# алгоритми точкової перевірки\n",
    "models = []\n",
    "models.append(( 'LR' , LogisticRegression()))\n",
    "models.append(( 'LDA' , LinearDiscriminantAnalysis()))\n",
    "models.append(( 'KNN' , KNeighborsClassifier()))\n",
    "models.append(( 'CART' , DecisionTreeClassifier()))\n",
    "models.append(( 'NB' , GaussianNB()))\n",
    "models.append(( 'SVM' , SVC()))\n",
    "\n",
    "# Варіанти тестування та метрика оцінювання\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7 \n",
    "scoring =  'accuracy'\n",
    "\n",
    "# Варіанти тестування та метрика оцінювання\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7 \n",
    "scoring =  'accuracy'\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    " kfold = KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    " cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    " results.append(cv_results)\n",
    " names.append(name)\n",
    " msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    " print(msg)\n",
    "print('-> 10-Fold cross-validation accurcay score for the training data for six classifiers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результати спостережень\n",
    "> Результати говорять про те, що як логістична регресія, так і LDA може бути вартим подальшого вивчення. Це просто середні значення точності. Завжди розумно дивитися на розподіл значень точності, обчислених у складі перехресної перевірки. Це можна виконати графічно, використовуючи графіки box та whisker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# порівняння алгоритмів\n",
    "fig = plt.figure()\n",
    "fig.suptitle( 'Algorithm Comparison' )\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результати спостережень\n",
    "> Усі класифікатори, окрім SVM, показують аналогічний жорсткий розподіл, що є обнадійливим, бо пропонують низьку дисперсію. Дивують погані результати SVM.\n",
    "> Можливо, що різноманітний розподіл атрибутів може вплинути на точність таких алгоритмів, як SVM.\n",
    "\n",
    "### Оцінка алгоритмів: стандартизація даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стандартизація набору даних\n",
    "pipelines = []\n",
    "pipelines.append(( 'ScaledLR' , Pipeline([( 'Scaler' , StandardScaler()),( 'LR' ,\n",
    "    LogisticRegression())])))\n",
    "pipelines.append(( 'ScaledLDA' , Pipeline([( 'Scaler' , StandardScaler()),( 'LDA' ,\n",
    "    LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(( 'ScaledKNN' , Pipeline([( 'Scaler' , StandardScaler()),( 'KNN' ,\n",
    "    KNeighborsClassifier())])))\n",
    "pipelines.append(( 'ScaledCART' , Pipeline([( 'Scaler' , StandardScaler()),( 'CART' ,\n",
    "    DecisionTreeClassifier())])))\n",
    "pipelines.append(( 'ScaledNB' , Pipeline([( 'Scaler' , StandardScaler()),( 'NB' ,\n",
    "    GaussianNB())])))\n",
    "pipelines.append(( 'ScaledSVM' , Pipeline([( 'Scaler' , StandardScaler()),( 'SVM' , SVC())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "  kfold = KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "  cv_results = cross_val_score(model, X_train, y_train, cv=kfold,\n",
    "      scoring=scoring)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# порівняння алгоритмів\n",
    "fig = plt.figure()\n",
    "fig.suptitle( 'Scaled Algorithm Comparison' )\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результати спостережень\n",
    "> Результати показують, що стандартизація даних підвищила результативність SVM настільки, що він став найточнішим серед усіх алгоритмів.\n",
    "\n",
    "Отримані результати пропонують розгянути у алгоритми SVM та LDA та LR. Дуже ймовірно, що додаткова їх конфігураці може дати ще більш точні моделі."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Налаштування алгоритмів\n",
    "\n",
    "#### Налаштування гіпер-параметрів SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# робимо SVC Pipeline\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()),\n",
    "                     ('pca', PCA(n_components=2)),\n",
    "                     ('clf', SVC(probability=True, verbose=False))])\n",
    "\n",
    "# підгін параметрів Pipeline до навчальних даних\n",
    "pipe_svc.fit(X_train, y_train)\n",
    "\n",
    "#print('--> Fitted Pipeline to training Data')\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_svc, X=X_train, y=y_train, cv=10, n_jobs=1, verbose=0)\n",
    "print('--> Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "# налаштування гіпер-параметрів\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'clf__C': param_range,'clf__kernel': ['linear']},\n",
    "              {'clf__C': param_range,'clf__gamma': param_range,\n",
    "               'clf__kernel': ['rbf']}]\n",
    "gs_svc = GridSearchCV(estimator=pipe_svc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  n_jobs=1)\n",
    "gs_svc = gs_svc.fit(X_train, y_train)\n",
    "print('--> Tuned Parameters Best Score: ',gs.best_score_)\n",
    "print('--> Best Parameters: \\n',gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Налаштування гіперпараметрів k-NN\n",
    "Для стандартної реалізації k-NN, необхідно налаштувати два основні гіпер-параметри:\n",
    "* кількість сусідів k;\n",
    "* функція відстаней метрик/подібностей.\n",
    "\n",
    "Обидва ці значення можуть різко вплинути на точність класифікатора k-NN. Об'єкт Grid може виконати 10-кратну крос-валідацію на моделі KNN, використовуючи класифікаційну точність як метрику оцінювання.\n",
    "Крім того, за допомогою сітки параметрів можна повторити 10-кратну крос-валідацію 30 разів.\n",
    "Кожного разу параметру n_neighbors слід надавати інше значення зі списку.\n",
    "Не можна надати GridSearchCV тільки список.\n",
    "Необхідно вказати, що n_ouighbors має приймати значення від 1 до 30.\n",
    "Можна встановити n_jobs = -1 для паралельних обчислень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "pipe_knn = Pipeline([('scl', StandardScaler()),\n",
    "                     ('pca', PCA(n_components=2)),\n",
    "                     ('clf', KNeighborsClassifier())])\n",
    "            \n",
    "# підгін параметрів Pipeline до навчальних даних\n",
    "pipe_knn.fit(X_train, y_train) \n",
    "\n",
    "scores = cross_val_score(estimator=pipe_knn, \n",
    "                         X=X_train, \n",
    "                         y=y_train, \n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('--> Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "# налаштування гіперпараметрів\n",
    "param_range = range(1, 31)\n",
    "param_grid = [{'clf__n_neighbors': param_range}]\n",
    "# встановлення сітки\n",
    "grid = GridSearchCV(estimator=pipe_knn, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=10, \n",
    "                    scoring='accuracy')\n",
    "gs_knn = grid.fit(X_train, y_train)\n",
    "print('--> Tuned Parameters Best Score: ',gs.best_score_)\n",
    "print('--> Best Parameters: \\n',gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Допрацювання моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# використання найкращих параметрів\n",
    "clf_svc = gs.best_estimator_\n",
    "\n",
    "#Get Final Scores\n",
    "clf_svc.fit(X_train, y_train)\n",
    "scores = cross_val_score(estimator=clf_svc,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('--> Final Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "print('--> Final Accuracy on Test set: %.5f' % clf_svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Висновок\n",
    "\n",
    "Опрацьовано класифікаційне прогностичне моделювання використовуючи машинне навчання за допомогою Python. Зокрема, розглянуті та реалізовані наступні кроки:\n",
    "1. Визначення проблеми (дані про рак молочної залози);\n",
    "2. Завантаження вхідного набору даних;\n",
    "3. Аналіз даних (однаковий масштаб, але різний розподіл даних):\n",
    "    * оцінка алгоритму (KNN має гарні результати);\n",
    "    * оцінка алгоритів зі стандартизацією (KNN та SVM мають гарні результати);\n",
    "4. Налаштування алгоритму (К=19 для KNN мав гарні результати; SVM з RBF ядром та K=100 мав найкращі);\n",
    "5. Допрацювання моделі (використання усіх навчальних даних та перевірка на тестовому наборі даних)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
